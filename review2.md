KGNv2: RGB-D 입력에서 키포인트 기반 6-DoF 그래스프 합성을 위한 스케일 및 포즈 예측 분리
본 논문은 RGB-D 이미지에서 로봇 그리퍼의 6-DoF(6 자유도) 그래스프 포즈를 추정하는 개선된 키포인트 기반 접근 방식인 KGNv2를 제안하고 있습니다. 새로운 방법론적 접근을 통해 정확성과 일반화 능력을 향상시켰으며, 다양한 객체 형태와 환경에서 강건한 성능을 보여줍니다.

초록(Abstract)
연구자들은 2D/2.5D 입력에서 키포인트를 기반으로 한 새로운 6-DoF 그래스프 포즈 합성 접근 방식을 제안했습니다. 이미지 입력을 사용한 키포인트 기반 그래스프 감지 방법은 이전 연구에서 유망한 결과를 보여주었지만, 이미지 공간에서 키포인트의 정확한 위치 예측에 크게 의존합니다. 이러한 문제를 해결하기 위해 정확한 키포인트 예측에 대한 의존성을 줄이는 새로운 그래스프 생성 네트워크를 개발했습니다.

KGNv2는 RGB-D 입력이 주어지면 키포인트 감지를 통한 그래스프 포즈와 카메라 방향의 스케일을 모두 예측합니다. 또한 키포인트 출력 공간을 재설계하여 Perspective-n-Point(PnP) 알고리즘에 대한 키포인트 예측 노이즈의 부정적 영향을 완화했습니다. 이러한 간단한 수정은 실험에서 기준 모델인 KGN보다 크게 향상된 성능을 보여주었으며, 단순한 합성 객체로만 훈련했음에도 실제 물체와 환경에서 잘 일반화됨을 입증했습니다.

기여(Contributions)
이 논문의 주요 기여는 다음과 같습니다:

1. 분리된 스케일 및 포즈 예측
원래의 KGN 모델은 키포인트 근접성 예측에 크게 의존했으며, 이는 특히 합성 데이터에서 학습하고 실제 환경에서 테스트할 때 불안정한 결과를 초래했습니다. KGNv2는 포즈와 스케일을 별도로 예측함으로써 정확한 키포인트 근접성 추정의 필요성을 제거했습니다.

2. 스케일 정규화 키포인트 설계
키포인트 출력 공간을 추정된 스케일로 정규화하도록 재설계하여 키포인트 오류에 대한 민감성을 줄이고 추정된 포즈의 정밀도를 향상시켰습니다. PnP 알고리즘에 대한 수치 분석을 통해 스케일이 큰 그래스프 포즈(카메라에서 더 멀리 있는 포즈)가 노이즈에 더 민감하다는 것을 발견하고, 이를 해결하기 위한 설계를 제안했습니다.

3. 성능 향상 및 일반화
제안된 수정 사항들은 간단하지만 효과적이어서, Primitive Shape 데이터셋의 모든 테스트에서 그래스프 예측 성능을 크게 향상시켰습니다. 특히 복잡한 다중 객체 환경에서 GSR, GCR, OSR 메트릭에서 각각 27.8%, 17.8%, 6.6%의 성능 향상을 달성했습니다.

방법론(Method)
문제 정의
단안 RGB-D 입력이 주어졌을 때, 입력을 3D 표현(예: 포인트 클라우드)으로 변환하지 않고 6-DoF 그래스프 포즈 g ∈ SE(3)와 관련 그리퍼 개방 폭 w를 합성하는 것이 목표입니다.

주요 컴포넌트
1. 스케일 정규화 키포인트를 통한 포즈 추정
KGNv2는 키포인트 기반 전략을 채택하여 카메라 3D-2D 투영 원리를 활용해 스케일까지의 그래스프 포즈를 추정합니다. 네트워크는 다음을 예측합니다:

각 방향 간격에 대한 그래스프 중심 집합 {c^m_i}

중심-키포인트 오프셋 벡터 맵 O

이 설계는 여러 그래스프를 동시에 감지할 수 있게 하고, 회전 대칭 객체에 대한 다양한 후보군 생성에 유용합니다.

스케일 정규화 키포인트 설계는 다음과 같습니다:

text
O_c = Õ_c / S_c
여기서 Õ_c는 실제 오프셋 벡터이고, S_c는 예측된 스케일입니다.

2. 스케일 예측
KGNv2는 각 픽셀과 방향에 대해 직접 스케일 맵 S ∈ R^(H'×W'×M)을 예측합니다. 예측된 스케일을 사용하면 PnP 알고리즘에서 얻은 변환 크기를 쉽게 개선할 수 있습니다:

text
ĝ = {R̂, T̂} = {R̃, (S_c,m / ||T̃||) · T̃}
여기서 R̃과 T̃는 PnP 알고리즘에서 얻은 회전과 변환입니다.

3. 네트워크 아키텍처 및 학습
비전 인코더로 DLA-34 사용 (4채널 RGB-D 입력용으로 수정)

각 작업 헤드에 얕은 2층 컨볼루션 네트워크 사용

최종 손실 함수:

text
L = γY·LY + γO·LO + γW·LW + γS·LS
(γY = 1, γO = 1, γW = 10, γS = 10)

실험 결과 및 결론
합성 데이터셋 실험
Primitive Shape 데이터셋에서 KGNv2는 모든 설정에서 기준 KGN을 크게 능가했습니다:

다중 객체 데이터로 학습하고 테스트했을 때, 가장 엄격한 임계값 조건에서 GSR, GCR, OSR에서 각각 27.8%, 17.8%, 6.6%의 성능 향상

단일 객체 장면에서 학습하고 더 복잡한 다중 객체 시나리오에서 테스트했을 때, 10.6%, 9.8%, 14.2%의 성능 향상을 기록

절제 연구를 통해 두 가지 주요 수정 사항(스케일 분기와 스케일 정규화 키포인트)이 모두 성능 향상에 기여한다는 것을 입증했습니다.

실제 로봇 실험
실제 환경에서의 실험을 통해 합성-현실 격차에 대한 일반화 능력을 검증했습니다:

단일 객체 그래스핑: 92.5 ± 6.7% 성공률 (KGN의 87.5 ± 9.6%보다 향상)

다중 객체 그래스핑: 80 ± 10.1% 성공률, 96 ± 7.4% 정리율

결론
이 연구는 RGB-D 이미지 입력에서 6-DoF 그래스프 포즈를 더 정확하게 감지할 수 있는 개선된 방법을 제시했습니다. KGNv2의 핵심 혁신은 포즈와 스케일 예측을 분리하고, 스케일 정규화된 키포인트를 설계한 것입니다. 이러한 수정은 키포인트 예측 오류에 대한 민감성을 줄이고, 다양한 환경에서 그래스프 예측 성능을 크게 향상시켰습니다.

단순한 합성 기본 형태에 대해서만 학습되었음에도 불구하고, KGNv2는 실제 물체에 대한 실험에서 경쟁력 있는 성능을 보여주었습니다. 이는 기하학적 정보를 효과적으로 학습하고 실제 환경에 일반화할 수 있음을 입증합니다.

향후 연구 방향으로는 확산 모델과 같은 생성 방법을 활용하여 진정한 텍스처로 데이터셋을 확장하는 방법을 탐색할 수 있을 것입니다.
