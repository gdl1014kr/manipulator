# Learning robust, real-time, reactive robotic grasping

## 초록(abstract)

 **GG-CNN(Generative Grasping Convolutional Neural Network)**: deep learning을 통해 input된 depth image의 **각 pixel(카메라로부터 해당 위치의 물체까지의 거리)**에 대해 grasp 품질(Quality)(성공 확률), grasp 각도(Angle), grasp 너비(Width)를 동시에 예측
 (대규모 데이터셋을 통해 grasp 성공 확률이 높은 위치, 각도, 너비 등을 예측하는 방법을 학습)
=> 가장 높은 품질의 pixel을 찾아 최적의 grasp 자세 결정. 낯선 물체 및 다양한 특성을 가진 물체, 동적인 환경(주변 환경이 실시간으로 변하거나 물체가 움직이는 환경), 센서 노이즈 및 제어 오차, 복잡한 환경(물체가 무질서하게 밀집되어 있거나 가려짐.) (clutter)에서도 높은 그립 성공률(실시간)
  한 번의 네트워크 추론으로 영상 전체에서 가능한 모든 그리핑을 평가할 수 있다. 이 방식은 기존의 후보 샘플링-평가 방식보다 훨씬 빠르고, 실시간 제어에 적합하다. 네트워크 구조는 매우 경량화되어(약 62,000개 파라미터) GPU가 탑재된 임베디드 시스템에서도 동작
   다중 시점(multi-view) 융합 방법
요약하자면, 이 논문은 딥러닝을 통해 깊이 이미지만으로 물체의 **픽셀 단위 파지 맵(pixel-wise grasp map)**을 실시간으로 생성하는 새로운 신경망 모델(GG-CNN)을 제안하고, 이를 폐쇄 루프 방식으로 로봇 제어에 활용하여 처음 보는 물체, 움직이는 물체, 복잡한 환경 등 다양한 도전적인 상황에서도 강건하게 파지를 수행하는 방법을 제시합니다.

최적 파지 자세- 로봇 그리퍼가 물체를 잡기 위해 도달해야 하는 3차원 공간에서의 위치(x,y,z), z축을 중심으로 한 회전 각도, 그리퍼가 벌려야할 너
왜 다중 시점 방식이 필요한가요?
로봇이 물체가 복잡하게 쌓여 있는 '클러터(clutter)' 환경에서 파지할 때, 한 시점에서는 다른 물체에 가려져(occlusion) 파지에 적합한 물체의 특정 부분이 보이지 않을 수 있습니다.
또한, 깊이 카메라 자체의 한계로 인해 특정 재질(예: 반사되거나 투명하거나 검은색 물체)에 대한 깊이 정보가 부정확하거나 누락될 수 있습니다.


다중 시점 방식은 어떻게 작동하나요?
이 논문에서 제안하는 GG-CNN 모델은 깊이 이미지를 입력받아 해당 시점에서 볼 수 있는 모든 픽셀에 대해 파지 품질, 각도, 너비 등의 정보를 예측하는 '픽셀 단위 파지 맵'을 생성합니다.
다중 시점 방식에서는 로봇이 여러 다른 위치나 경로를 따라 이동하면서 여러 장의 깊이 이미지를 촬영하고, 각 이미지에서 GG-CNN으로 생성된 파지 맵 정보들을 수집합니다.
수집된 여러 시점의 파지 정보들은 작업 공간을 격자 형태로 나눈 '그립 맵(grip map)'에 누적되어 조합됩니다. 각 격자 셀에 대해 여러 시점에서 관측된 파지 품질, 각도, 너비 정보들의 평균을 계산하여 최종 파지 후보를 결정합니다.


다중 시점 방식이 파지 성공률을 어떻게 높이나요?
여러 시점에서 얻은 정보를 조합함으로써, 한 시점에서는 가려져 보이지 않았던 좋은 파지 지점을 발견할 수 있습니다.
다양한 각도에서 물체를 관찰하며 깊이 카메라의 측정 오류나 노이즈로 인한 부정확한 예측을 보완하고, 더 정확하고 신뢰할 수 있는 파지 정보를 얻을 수 있습니다.
특히 클러터 환경에서 물체들 사이에 숨겨진 최적의 파지 지점을 찾아내거나, 잘못된 파지 예측(false positive) 가능성이 있는 영역의 신뢰도를 낮추는 효과를 얻을 수 있습니다.


## 방법론
현실 공간에서의 파지 정의 (\(g\)):

논문은 로봇이 물체를 잡는 '파지(grasp)'를 \(g = (q, p, \phi, w)\) 라는 네 가지 정보의 조합으로 정의합니다. 여기서 로봇의 그리퍼는 x-y 평면에 수직으로 내려가서 물체를 잡는다고 가정합니다.
\(q\) (품질, quality): 파지 성공 확률을 나타내는 0과 1 사이의 스칼라 값입니다. 1에 가까울수록 성공 가능성이 높습니다.
\(p = (x, y, z)\) (위치, position): 월드 좌표계(로봇 기준)에서의 그리퍼 중심 위치입니다.
\(\phi\) (각도, rotation): z축을 중심으로 한 그리퍼의 회전 각도입니다.
\(w\) (너비, width): 파지를 위해 필요한 그리퍼의 벌어진 너비입니다. 기존 연구들 중에는 그리퍼 너비를 고정하거나 고려하지 않는 경우가 많았지만, 이 논문에서는 너비 예측을 통해 클러터 환경 등에서 성능 향상을 도모합니다.


이미지 공간에서의 파지 정의 (\(\tilde{g}\)):

입력으로 사용되는 깊이 이미지 \(I\) (높이 H, 너비 W) 상에서 파지는 \(\tilde{g} = (q, \tilde{s}, \tilde{\phi}, \tilde{w})\) 로 정의됩니다.
\(q\) (품질, quality): 현실 공간과 동일하게 파지 성공 확률을 나타냅니다.
\(\tilde{s} = (u, v)\) (중심점, center point): 이미지 좌표계(픽셀)에서의 파지 중심점 위치입니다.
\(\tilde{\phi}\) (각도, rotation): 카메라 기준 좌표계에서의 회전 각도입니다. 반대칭 파지(antipodal grasp)의 특성 상, 각도는 \(\left[ -\frac{\pi}{2}, \frac{\pi}{2} \right]\) 범위 내에 있습니다. (논문에서는 이 각도를 \(\sin(2\tilde{\phi})\)와 \(\cos(2\tilde{\phi})\) 두 개의 요소로 인코딩하여 신경망 학습을 용이하게 합니다.)
\(\tilde{w}\) (너비, width): 이미지 좌표계에서의 파지 너비입니다 (픽셀 단위, 최대 150 픽셀). 이는 카메라 파라미터와 해당 픽셀의 깊이를 이용해 현실 공간의 물리적 너비로 변환할 수 있습니다.


이미지 공간 파지를 현실 공간 파지로 변환하는 과정:

깊이 이미지 상에서 정의된 파지 \(\tilde{g}\)는 알려진 변환 과정을 거쳐 현실 공간의 파지 \(g\)로 변환됩니다. 이 과정은 아래의 수식 (1)로 표현됩니다.
수식 (1):
\[ g = t_{RC} (t_{CI} (\tilde{g})) \quad (1) \]
\(g\): 현실 공간(월드/로봇 프레임)에서의 파지 자세입니다.
\(t_{RC}\): 카메라 프레임에서 월드/로봇 프레임으로 변환하는 과정입니다.
\(t_{CI}\): 2차원 이미지 좌표 및 깊이 정보(\(\tilde{g}\)에 포함)를 3차원 카메라 프레임 좌표로 변환하는 과정입니다. 카메라 고유 파라미터와 로봇-카메라 간의 보정 정보를 이용합니다.
\(\tilde{g}\): 2차원 깊이 이미지 상에서 정의된 파지 정보입니다.
파지의 깊이(\(z\) 값)는 그리퍼 손가락 끝이 측정된 깊이와 일치하도록 일정량의 오프셋이 적용됩니다.


파지 맵 정의 (\(\tilde{G}\)):

논문에서는 GG-CNN이 예측하는 최종 결과물을 '파지 맵(grasp map)' \(\tilde{G}\)로 정의합니다. 이는 이미지 공간에서의 파지 정보들을 모아놓은 것으로, \(\tilde{G} = (\tilde{Q}, \tilde{F}, \tilde{W}) \in \mathbb{R}^{3 \times H \times W}\) 형태를 가집니다.
\(\tilde{Q}\): 각 픽셀 \((u, v)\)에서의 파지 품질 \(q\)를 나타내는 HxW 크기의 이미지입니다.
\(\tilde{F}\): 각 픽셀 \((u, v)\)에서의 파지 각도 \(\tilde{\phi}\)를 나타내는 HxW 크기의 이미지입니다. (실제로는 \(\sin(2\tilde{\phi})\)와 \(\cos(2\tilde{\phi})\) 채널로 구성됩니다.)
\(\tilde{W}\): 각 픽셀 \((u, v)\)에서의 필요한 그리퍼 너비 \(\tilde{w}\)를 나타내는 HxW 크기의 이미지입니다.
즉, 파지 맵은 깊이 이미지의 각 픽셀에 대해 해당 위치에서 파지를 시도할 때의 품질, 각도, 너비를 조밀하게 담고 있습니다.


최적 파지 도출:

신경망은 깊이 이미지 \(I\)를 입력받아 함수 \(M\)을 통해 파지 맵 \(\tilde{G}\)를 예측합니다. \(M(I) = \tilde{G}\).
이미지 공간에서 가장 품질이 높은 파지 \(\tilde{g}^*\)는 파지 맵 \(\tilde{G}\) 중 \(\tilde{Q}\) 값이 최대인 픽셀 위치에서 얻어지며, 해당 위치의 \(\tilde{F}\)와 \(\tilde{W}\) 값을 사용합니다.
이후 수식 (1)을 적용하여 현실 공간에






   
## 구체적 설명

### 1. 연구 배경 및 기존 한계

기존의 로봇 grasp 기술: 이미지 상에서 파지할 만한 후보 위치들을 몇 개 **샘플링(sampling)**하고, 각 후보에 대해 파지 성공 가능성 점수를 매겨 **순위(ranking)**를 매기는 방식
Open-loop grasping는 처음에 한 번 파지 계획을 세우고 나면 동작 도중에 환경 변화에 반응하지 않고 그대로 실행하는 방식. 처음에 계산된 고정된 목표 자세로만 이동하기 때문에 물체가 이동하면 목표 지점에서 벗어나 파지에 실패할 가능성이 높습니다. +  환경이 완전히 정적이어야 하거나 카메라 및 로봇의 정밀한 캘리브레이션 및 제어에 의존해야 한다는 단점
여러 후보 grasp 위치를 이산적으로 샘플링하고 각 후보마다 평가 진행하여 계산 시간이 오래걸려 Closed-loop control(파지 동작 중에 실시간으로 주변 환경 정보를 받아들이고 이를 바탕으로 로봇의 움직임을 수정하며 목표 파지 자세로 나아가는 방식. 로봇이 물체를 향해 이동하는 도중에도 센서로부터 새로운 정보를 받아들여 파지 목표 자세를 계속 업데이트.로봇이 실시간으로 환경 변화를 반영해 그리핑 움직임을 수정하는 것)에 적합하지 x, 또한 복잡하거나 혼잡한 환경에서 성능이 크게 저하.
=> closed-loop control의 장점: 동적 환경 적응, 정확도 요구사항 완화(카메라와 로봇 간의 정밀한 캘리브레이션이나 로봇 위치 제어의 정확도에 덜 의존적-실제 환경에서 발생할 수 있는 불확실성에 강건하게 대처)

### 2. 폐루프(Closed-loop) 제어의 장점

GG-CNN의 속도와 경량성 덕분에, 로봇은 초당 50회(50Hz) 깊이 영상을 받아 실시간으로 그리핑 위치를 계속 업데이트할 수 있다. 즉, 물체가 움직이거나, 로봇 팔의 미세한 오차가 발생해도, 로봇은 새로운 영상을 받아 즉각적으로 그리핑 경로를 수정한다. 이로써 기존의 오픈루프(한 번 예측 후 그대로 실행) 방식보다 훨씬 더 견고하게 다양한 상황에 대응할 수 있다. 


### 3. 의의와 한계

이 연구는 로봇이 다양한 환경에서 빠르고 견고하게 물체를 잡을 수 있게 해주는 실질적 방법론을 제시한다. 특히, 폐루프 제어의 실시간성, 경량화된 네트워크 구조, 혼잡 환경에서의 강건성 등은 실제 산업 현장이나 서비스 로봇에 바로 적용할 수 있는 큰 장점이다. 다만, 깊이 센서에 의존하기 때문에 투명하거나 반사율이 높은 물체, 혹은 고도로 복잡한 표면에서는 성능이 저하될 수 있다. 향후에는 촉각 센서와의 융합, RGB-D 정보 통합, 다지 그리퍼 확장 등이 연구 방향이 될 수 있다

**요약**  
이 논문은 GG-CNN이라는 경량 합성곱 신경망을 통해, 깊이 영상 기반의 실시간, 객체 독립적, 폐루프 로봇 그리핑을 실현했다. 기존 방식의 느린 속도, 후보 샘플링 한계, 환경 변화에 대한 취약성을 극복하며, 실제 환경에서 높은 성공률과 실시간성을 입증했다. 
