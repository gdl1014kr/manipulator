좋아, 2020년 이후 발표된 depth image 기반 또는 point cloud 기반 upsampling 알고리즘 중에서 딥러닝(CNN 등)을 활용한 최신 학술 논문을 조사할게. 특히 Jetson AGX Orin과 같은 온디바이스 적용 가능성을 고려해 경량화나 실시간성에 주목하며 정리해서 알려줄게.

조사가 끝나면 핵심 알고리즘 구조, 성능 지표(FPS 포함), 온디바이스 적용 가능성 등을 포함한 보고서 형태로 요약해드릴게.


# 최신 RGB-D 기반 Depth/Point-Cloud 업샘플링 기법 조사

## Depth 이미지 업샘플링 기법

### FDSR (He et al., CVPR 2021)

FDSR는 **고속 경량 CNN** 구조를 이용해 RGB 가이드로부터 저해상도(depth) 이미지를 고해상도로 복원한다. 입력 RGB에서 고주파 성분을 추출하는 *고주파 유도 분지*(HFGB: High-Frequency Guidance Branch)와 다중 스케일 업샘플링 분지(MSRB: Multi-Scale Reconstruction Branch)로 구성된다. HFGB가 색상 이미지를 통해 경계 정보를 제공하면, MSRB가 단순 합성곱 블록과 업샘플링(픽셀 셔플)으로 점진적으로 해상도를 높인다. FDSR는 효율적인 연산을 사용하도록 설계되어, Titan XP GPU(640×480)에서 한 장당 \*\*0.01초(약 100FPS)\*\*로 동작한다. NYU v2 데이터셋 4× 업샘플링 기준 RMSE는 약 **1.61cm**로, 기존 DKN(1.62cm)보다 성능이 우수하다.

| 방법 (Method)     | 4× RMSE (NYUv2) | 8× RMSE (NYUv2) | 추론시간 (Titan XP, 640×480) |
| --------------- | --------------- | --------------- | ------------------------ |
| **FDSR (본 연구)** | 1.61 cm         | 3.18 cm         | 0.01 s (≈100FPS)         |
| DKN \[16]       | 1.62 cm         | 3.26 cm         | 0.17 s                   |
| FDKN \[16]      | 1.86 cm         | 3.58 cm         | 0.01 s                   |

* **온디바이스 적합성:** FDSR는 설계 단계부터 경량화되어 있어 실시간성이 뛰어나다. 실제 플랫폼(예: Jetson AGX Orin)에서도 최적화한다면 30FPS 이상으로 실행 가능할 것으로 보인다.

### 단일 깊이 영상 구조 유도 (Sun et al., CVPR 2021)

Sun et al.은 RGB 정보 없이 단일 저해상도(depth) 영상만으로 고해상도(depth SR)를 수행하기 위해 **교차 태스크 학습**을 도입했다. 훈련 시 RGB→depth 추정(Depth Estimation) 태스크와 depth SR 태스크를 함께 학습하여, RGB 기반 구조 정보를 단일-Depth SR 네트워크로 전이(distillation)한다. 구체적으로 두 개의 네트워크(하나는 저해상도 depth→고해상도 depth, 다른 하나는 RGB→depth)로 학습하며, 양방향 지식 전이 모듈과 추가적인 **구조 예측 구조(prediction) 태스크**를 통해 깊이 맵의 형태 정보를 강화한다. 이 방법으로 NYU v2 데이터셋에서 4× 업샘플링 RMSE가 약 **1.49cm**(DKN 1.62cm)로 종전 기법보다 크게 개선되었다.

| 방법 (Method)                   | 4× RMSE (NYUv2) | 8× RMSE (NYUv2) |
| ----------------------------- | --------------- | --------------- |
| **구조 유도 (본 연구)** (Sun et al.) | 1.49 cm         | 2.73 cm         |
| DKN \[21]                     | 1.62 cm         | 3.26 cm         |
| DJFR \[27]                    | 3.38 cm         | 5.86 cm         |

* **온디바이스 적합성:** DBPN 블록 등 깊은 네트워크와 두 개의 분기 구조를 사용하기 때문에 비교적 무겁다. 실시간 처리를 위해서는 경량화 또는 양자화 등의 추가 최적화가 필요할 수 있다.

### 깊이 확산 결합 CNN (Metzger et al., CVPR 2023)

Metzger et al.은 **CNN과 고전적 anisotropic diffusion**을 결합한 새로운 가이드형(depth-guided) SR 방법을 제안했다. 네트워크는 RGB에서 에지 정보를 추출하여 확산 계수(diffusion coefficients)를 학습하고, 이 계수에 따라 깊이 이미지를 반복적으로 확산(smoothing)시킨다. 결과에 대한 엄격한 보정(adjustment) 단계를 거쳐 최종 HR 깊이맵을 얻는다. 이론적 최적화와 딥러닝을 통합하여 더 큰 업샘플링 배율(예: ×32)에서도 뛰어난 성능을 보이며, Middlebury 등 벤치마크에서 **가장 낮은 RMSE**를 달성했다.

* **온디바이스 적합성:** 반복적인 확산 계산을 수반하여 계산 비용이 매우 높다. 현재까지는 실시간 처리를 목표로 설계되지 않았으며, Jetson과 같은 임베디드 시스템에 적용하려면 대대적 최적화가 필요하다.

## Point Cloud 업샘플링 기법

### PU-GCN (Qian et al., CVPR 2021)

PU-GCN은 **그래프 컨볼루션** 기반의 포인트 클라우드 업샘플링 네트워크다. 지역적 포인트 특징을 학습하는 Inception DenseGCN 구조와 새로 제안된 NodeShuffle 모듈을 결합하여, 다중 스케일 그래프 컨볼루션으로 포인트를 업샘플링한다. NodeShuffle는 그래프 컨볼루션으로 특징 채널을 r배 확장한 뒤 셔플해 새로운 포인트를 생성한다. PU-GCN은 PU-Net/3PU/PU-GAN 등 기존 기법을 능가하는 성능을 보이면서도 파라미터 수와 추론 시간을 대폭 절감했다.

* **온디바이스 적합성:** 기존 방법들보다 파라미터 수가 적고 연산량도 효율적이므로 비교적 경량한 편이다. 그래프 연산 특성상 완전한 실시간 처리는 어렵지만, GPU에서 수십 FPS급으로 동작 가능하여 Jetson Orin에서도 최적화 시 현실적인 처리율을 기대할 수 있다.

### PU-Transformer (Qiu et al., ACCV 2022)

PU-Transformer는 점군 업샘플링에 트랜스포머(Self-Attention)를 도입한 최초의 모델이다. 이 모델은 각 포인트의 기하학적 위치와 특징을 결합한 **Positional Fusion 블록**을 통해 3D 공간 정보를 인코딩하고, 연속적인 Transformer 인코더 층을 패치 기반으로 적용한다. 최종적으로 MLP를 통해 업샘플된 점들의 좌표를 생성한다. PU-Transformer는 3D 벤치마크에서 기존 CNN 기반 업샘플링 기법을 큰 폭으로 앞서는 성능을 보였다.

* **온디바이스 적합성:** 트랜스포머 구조 특성상 모델 크기와 연산량이 크며, 현재 속도 최적화가 충분치 않다. 저자도 “실시간 애플리케이션을 위해 효율성을 개선해야 한다”고 언급했으며, Jetson Orin에서는 실시간 운용을 위해 추가적인 경량화/양자화가 요구된다.

### TULIP (Yang et al., CVPR 2024)

TULIP은 **LiDAR 점군을 레인지 이미지로 변환**하여 Super-Resolution을 수행하는 Swin-Transformer 기반 네트워크이다. 종래의 SR 기법을 적용하되, LiDAR 특성(4×1 패치, 비정방 윈도우 등)에 맞춰 패치와 윈도우 형태를 수정하여 수평·수직 해상도 불균형을 보완했다. KITTI 등 대규모 데이터셋 실험에서, TULIP은 Chamfer 거리와 IoU 등 모든 평가 지표에서 기존 기법을 능가하며 **가장 우수한 성능**을 달성했다. 특히 불완전한 점군을 보정하여 노이즈 없는 결과를 생성한다.

* **온디바이스 적합성:** Swin-Transformer 블록을 많이 사용하므로 모델이 매우 크고 무겁다. 실시간 처리를 위해서는 모델 경량화가 필수적이며, Jetson Orin 단독으로는 높은 프레임레이트를 얻기 어려울 수 있다.

### PU-EdgeFormer (Kim et al., ICASSP 2023)

PU-EdgeFormer는 **그래프 컨볼루션(EdgeConv)과 트랜스포머(Self-Attention)를 결합**하여 포인트 업샘플링 성능을 향상시킨 모델이다. EdgeFormer 유닛은 EdgeConv로 국소 정보를 학습하고, 이어서 멀티-헤드 어텐션을 적용하여 전역 구조 의존성을 캡처한다. 실험 결과 PU-EdgeFormer는 기존 최첨단 기법보다 업샘플링 품질이 높음을 보였으며, 특히 노이즈가 많은 입력에서도 강건함을 보였다.

* **온디바이스 적합성:** 그래프 연산과 어텐션 블록이 결합된 구조이므로 연산량이 많다. 즉시 실시간 처리에는 무리가 있으며, 경량화 및 하드웨어 가속(예: TensorRT, CUDA 최적화)이 필요하다.

**참고:** 각 기법의 성능 비교는 위 표와 설명을 통해 요약되었다. **온디바이스 적합성**은 주로 파라미터 수, 연산 복잡도 및 보고된 추론 속도를 바탕으로 평가되었으며, 실시간/메모리 요구사항은 장치별 특성에 따라 달라질 수 있다.
